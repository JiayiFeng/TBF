#!/usr/bin/env python3
"""启动 TBF SFT 数据加载服务器。

这个脚本使用 mmq.data.sft_dataloader 中的 tbf_dataloader_start_at_batch_id 和 
tbf_to_records 函数来启动 TBF HTTP 服务器。
"""

import argparse
import os
import sys
import time
from tbf.dataloader_server import TBFBatchHTTPServer
from mmq.data.sft_tbf_dataloader import tbf_dataloader_start_at_batch_id, tbf_to_records
from functools import partial
from typing import Any

def _create_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="启动 TBF SFT 数据加载服务器")
    parser.add_argument("--host", default="127.0.0.1", help="服务器监听地址 (默认: 127.0.0.1)")
    parser.add_argument("--port", type=int, default=8999, help="服务器监听端口 (默认: 8999)")
    parser.add_argument("--prefetch-count", type=int, default=2, help="预取批次数量 (默认: 2)")
    parser.add_argument("--local-rank-count", type=int, default=8, help="本地 rank 数量 (默认: 8)")
    parser.add_argument("--data-dir", default="/tmp/tbf_local", help="存放batch数据的目录 (默认: /tmp/tbf_local)")
    parser.add_argument("--page-size", type=int, default=4096, help="页面大小（字节）(默认: 4096)")

    parser.add_argument(
        "--index_file",
        type=str,
        required=True,
        help="index file, generated by mmq_prepare_pretrain_data/mmq_batch_collator",
    )
    parser.add_argument(
        "--filename_transform",
        type=str,
        help="a sed string to transform filenames in index file",
    )
    parser.add_argument(
        "--start_iteration",
        type=int,
        default=None,
        help="start iteration for this dataset",
    )
    parser.add_argument(
        "--stop_iteration",
        type=int,
        default=None,
        help="stop iteration for this dataset",
    )
    parser.add_argument(
        "--micro_batch_size",
        type=int,
        help="micro batch size splitter",
    )
    parser.add_argument(
        "--micro_batch_splitter_strategy",
        type=str,
        help="micro batch splitter strategy",
        default="hint",
    )
    parser.add_argument(
        "--num_workers",
        type=int,
        help="number worker to load train data",
        default=1,
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda",
        choices=["cuda", "cpu"],
        help="not using anymore, always use cuda",
    )
    parser.add_argument(
        "--image_filename_transform",
        type=str,
        default=None,
        help="image file transformer",
    )
    parser.add_argument(
        "--varlen_batch_concat",
        type=bool,
        default=False,
        help="concat varlen batch as a non-varlen batch",
    )
    parser.add_argument(
        "--pretrain",
        type=bool,
        default=False,
        help="pretrain mode",
    )
    parser.add_argument(
        "--extra_args",
        type=dict[str, Any],
        default=None,
        help="extra args for dataset, mainly use in eval set",
    )

    return parser


def main():
    parser = _create_arg_parser()
    args = parser.parse_args()

    print("=" * 70)
    print("TBF SFT 数据加载服务器")
    print("=" * 70)
    print(f"配置:")
    print(f"  Host:              {args.host}")
    print(f"  Port:              {args.port}")
    print(f"  Prefetch Count:    {args.prefetch_count}")
    print(f"  Local Rank Count:  {args.local_rank_count}")
    print(f"  Data Directory:    {args.data_dir}")
    print(f"  Page Size:         {args.page_size} bytes")
    print("=" * 70)
    
    # 创建服务器
    server = TBFBatchHTTPServer(
        dataloader_start_at_batch_id=partial(tbf_dataloader_start_at_batch_id, dataset_args=args),
        to_records=tbf_to_records,
        prefetch_count=args.prefetch_count,
        local_rank_count=args.local_rank_count,
        local_dir=args.data_dir,
        page_size=args.page_size,
    )
    
    # 启动服务器
    server.start(host=args.host, port=args.port)
    
    print(f"\n✓ 服务器已启动: {server.base_url}")
    print(f"\n使用示例:")
    print(f"  - 获取当前批次ID: curl '{server.base_url}/current_batch_id?local_rank=0'")
    print(f"  - 跳转到批次:     curl -X POST '{server.base_url}/seek?batch_id=100'")
    print(f"  - 获取下一批次:   curl -X POST '{server.base_url}/fetch_next?local_rank=0'")
    print(f"\n按 Ctrl+C 停止服务器...")
    
    try:
        # 保持主线程运行
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n\n正在停止服务器...")
        server.stop()
        print("✓ 服务器已停止")


if __name__ == "__main__":
    main()
